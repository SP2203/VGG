{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7baa271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Configurable Parameters\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "LOSS = tf.keras.metrics.categorical_crossentropy\n",
    "OPTIMIZER = tf.keras.optimizers.SGD()\n",
    "METRIC = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a7a31ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errors(history, epochs):\n",
    "    # Plotting Train and Validation Loss\n",
    "\n",
    "    epochs_range = list(range(1, epochs + 1))\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(1, figsize=(10, 6))\n",
    "    plt.plot(epochs_range, train_loss, label='train_loss')\n",
    "    plt.plot(epochs_range, val_loss, label='validation_loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Categorical Cross Entropy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred, classes=[]):\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    cm_df = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "\n",
    "    plt.figure(1, figsize=(16, 8))\n",
    "    sns.set(font_scale=1.5, color_codes=True, palette='deep')\n",
    "    sns.heatmap(cm_df, annot=True, annot_kws={'size': 16}, fmt='d', cmap='YlGnBu')\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def model_training(model, X_train, y_train, X_cv, y_cv, epochs, \n",
    "                   batch_size,loss, optimizer, metrics):\n",
    "    \n",
    "    # Initialise optimizers\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    # Enabling Early Stopping\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "    # Enabling check point\n",
    "    mc = ModelCheckpoint(filepath='bestModel.h5', monitor='val_acc', \n",
    "                         mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "    # Model fitting\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_cv, y_cv), \n",
    "                        epochs=epochs, batch_size=batch_size,\n",
    "                        verbose=1, callbacks=[es, mc])\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb20f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG:\n",
    "    \n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "    \n",
    "    def model_initialise_vgg16(self):\n",
    "        \n",
    "        # Define the AlexNet Architecture\n",
    "        ip = Input(shape= self.input_shape)\n",
    "        \n",
    "        # 1st Convolutional Layer \n",
    "        x = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(ip)\n",
    "        \n",
    "        # 2nd Convolutional Layer\n",
    "        x = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # Max Pooling Layer\n",
    "        x = MaxPooling2D(pool_size = (2,2), padding=\"same\", strides=(2,2))(x)\n",
    "        \n",
    "        # 3rd Convolutional Layer\n",
    "        x = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 4th Convolutional Layer\n",
    "        x = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # Max Pooling Layer\n",
    "        x = MaxPooling2D(pool_size = (2,2), padding=\"same\", strides=(2,2))(x)\n",
    "        \n",
    "        # 5th Convolutional Layer\n",
    "        x = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 6th Convolutional Layer\n",
    "        x = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 7th Convolutional Layer\n",
    "        x = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # Max Pooling Layer\n",
    "        x = MaxPooling2D(pool_size = (2,2), padding=\"same\", strides=(2,2))(x)\n",
    "        \n",
    "        # 8th Convolutional Layer\n",
    "        x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 9th Convolutional Layer\n",
    "        x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 10th Convolutional Layer\n",
    "        x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # Max Pooling Layer\n",
    "        x = MaxPooling2D(pool_size = (2,2), padding=\"same\", strides=(2,2))(x)\n",
    "        \n",
    "        # 11th Convolutional Layer\n",
    "        x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 12th Convolutional Layer\n",
    "        x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 13th Convolutional Layer\n",
    "        x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # Max Pooling Layer\n",
    "        x = MaxPooling2D(pool_size = (2,2), padding=\"same\", strides=(2,2))(x)\n",
    "        \n",
    "        # Flattening\n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        # 1st Fully Connected Layer \n",
    "        x = Dense(units=4096, activation=\"relu\")(x)\n",
    "            \n",
    "        # 2nd Fully Connected Layer\n",
    "        x = Dense(units=4096, activation=\"relu\")(x)\n",
    "        \n",
    "        # Output Layer\n",
    "        op = Dense(units=self.output_shape, activation=\"softmax\")(x)\n",
    "        \n",
    "        # Define Model\n",
    "        model = Model(inputs=ip, outputs=op)\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def model_initialise_vgg19(self):\n",
    "        \n",
    "        # Define the AlexNet Architecture\n",
    "        ip = Input(shape= self.input_shape)\n",
    "        \n",
    "        # 1st Convolutional Layer \n",
    "        x = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(ip)\n",
    "        \n",
    "        # 2nd Convolutional Layer\n",
    "        x = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # Max Pooling Layer\n",
    "        x = MaxPooling2D(pool_size = (2,2), padding=\"same\", strides=(2,2))(x)\n",
    "        \n",
    "        # 3rd Convolutional Layer\n",
    "        x = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 4th Convolutional Layer\n",
    "        x = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # Max Pooling Layer\n",
    "        x = MaxPooling2D(pool_size = (2,2), padding=\"same\", strides=(2,2))(x)\n",
    "        \n",
    "        # 5th Convolutional Layer\n",
    "        x = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 6th Convolutional Layer\n",
    "        x = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 7th Convolutional Layer\n",
    "        x = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 8th Convolutional Layer\n",
    "        x = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # Max Pooling Layer\n",
    "        x = MaxPooling2D(pool_size = (2,2), padding=\"same\", strides=(2,2))(x)\n",
    "        \n",
    "        # 9th Convolutional Layer\n",
    "        x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 10th Convolutional Layer\n",
    "        x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 11th Convolutional Layer\n",
    "        x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 12th Convolutional Layer\n",
    "        x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # Max Pooling Layer\n",
    "        x = MaxPooling2D(pool_size = (2,2), padding=\"same\", strides=(2,2))(x)\n",
    "        \n",
    "        # 13th Convolutional Layer\n",
    "        x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 14th Convolutional Layer\n",
    "        x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 15th Convolutional Layer\n",
    "        x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # 16th Convolutional Layer\n",
    "        x = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", strides=(1,1), activation =\"relu\")(x)\n",
    "        \n",
    "        # Max Pooling Layer\n",
    "        x = MaxPooling2D(pool_size = (2,2), padding=\"same\", strides=(2,2))(x)\n",
    "        \n",
    "        # Flattening\n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        # 1st Fully Connected Layer \n",
    "        x = Dense(units=4096, activation=\"relu\")(x)\n",
    "            \n",
    "        # 2nd Fully Connected Layer\n",
    "        x = Dense(units=4096, activation=\"relu\")(x)\n",
    "        \n",
    "        # Output Layer\n",
    "        op = Dense(units=self.output_shape, activation=\"softmax\")(x)\n",
    "        \n",
    "        # Define Model\n",
    "        model = Model(inputs=ip, outputs=op)\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38c0c7b",
   "metadata": {},
   "source": [
    "## VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6fa3647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28) (60000,) (10000,)\n",
      "Size of each image = (32, 32, 1)\n",
      "Nos of Classes = 10\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset and perform splitting\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# Resize image to 32x 32\n",
    "X_train = np.array([np.pad(X_train[i], pad_width=2) for i in range(X_train.shape[0])])\n",
    "X_test = np.array([np.pad(X_test[i], pad_width=2) for i in range(X_test.shape[0])])\n",
    "\n",
    "# Performing reshaping operation\n",
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32, 32, 1)\n",
    "\n",
    "# Normalization\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# One Hot Encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Define image size and number of classes\n",
    "image_size = X_train.shape[1:]\n",
    "classes = y_train.shape[1]\n",
    "\n",
    "print(f\"Size of each image = {image_size}\")\n",
    "print(f\"Nos of Classes = {classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "232a5295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 33,637,066\n",
      "Trainable params: 33,637,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 268s 139ms/step - loss: 2.3013 - accuracy: 0.1122 - val_loss: 2.3004 - val_accuracy: 0.1135\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 258s 138ms/step - loss: 2.2995 - accuracy: 0.1124 - val_loss: 2.2952 - val_accuracy: 0.1135\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 256s 136ms/step - loss: 1.8166 - accuracy: 0.3396 - val_loss: 0.4521 - val_accuracy: 0.8445\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 253s 135ms/step - loss: 0.2031 - accuracy: 0.9369 - val_loss: 0.1184 - val_accuracy: 0.9614\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 0.0888 - accuracy: 0.9726 - val_loss: 0.0606 - val_accuracy: 0.9816\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 175s 93ms/step - loss: 0.0604 - accuracy: 0.9811 - val_loss: 0.0456 - val_accuracy: 0.9846\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 178s 95ms/step - loss: 0.0466 - accuracy: 0.9852 - val_loss: 0.0438 - val_accuracy: 0.9861\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 0.0359 - accuracy: 0.9890 - val_loss: 0.0358 - val_accuracy: 0.9887\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 0.0369 - val_accuracy: 0.9877\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 181s 96ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.0370 - val_accuracy: 0.9887\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    }
   ],
   "source": [
    "# Create model instance and initialise Lenet Model\n",
    "vgg = VGG(image_size, classes)\n",
    "model_vgg16 = vgg.model_initialise_vgg16()\n",
    "\n",
    "epochs = EPOCHS\n",
    "batch_size = BATCH_SIZE\n",
    "loss = LOSS\n",
    "optimizer = OPTIMIZER\n",
    "metric = METRIC\n",
    "model_vgg16, history = model_training(model_vgg16, X_train, y_train, X_test, y_test, \n",
    "                                      epochs, batch_size,\n",
    "                                      loss, optimizer, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a7548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trainning and test error\n",
    "plot_errors(history, min(epochs, len(history.history['loss'])))\n",
    "\n",
    "# Perform Prediction\n",
    "y_pred = model_vgg16.predict(X_test)\n",
    "\n",
    "# Get list of prediction\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a286a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Confusion Matrix\n",
    "plot_confusion_matrix(y_test, y_pred, list(range(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068a182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bae1bd3",
   "metadata": {},
   "source": [
    "## VGG 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b284f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset and perform splitting\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# Resize image to 32x 32\n",
    "X_train = np.array([np.pad(X_train[i], pad_width=2) for i in range(X_train.shape[0])])\n",
    "X_test = np.array([np.pad(X_test[i], pad_width=2) for i in range(X_test.shape[0])])\n",
    "\n",
    "# Performing reshaping operation\n",
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32, 32, 1)\n",
    "\n",
    "# Normalization\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# One Hot Encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Define image size and number of classes\n",
    "image_size = X_train.shape[1:]\n",
    "classes = y_train.shape[1]\n",
    "\n",
    "print(f\"Size of each image = {image_size}\")\n",
    "print(f\"Nos of Classes = {classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2307e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance and initialise Lenet Model\n",
    "vgg = VGG(image_size, classes)\n",
    "model_vgg19 = vgg.model_initialise_vgg19()\n",
    "\n",
    "epochs = EPOCHS\n",
    "batch_size = BATCH_SIZE\n",
    "loss = LOSS\n",
    "optimizer = OPTIMIZER\n",
    "metric = METRIC\n",
    "model_vgg19, history = model_training(model_vgg19, X_train, y_train, X_test, y_test, \n",
    "                                      epochs, batch_size,\n",
    "                                      loss, optimizer, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2304dc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trainning and test error\n",
    "plot_errors(history, min(epochs, len(history.history['loss'])))\n",
    "\n",
    "# Perform Prediction\n",
    "y_pred = model_vgg19.predict(X_test)\n",
    "\n",
    "# Get list of prediction\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db139f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Confusion Matrix\n",
    "plot_confusion_matrix(y_test, y_pred, list(range(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce341a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60896afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonNew",
   "language": "python",
   "name": "pythonnew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
